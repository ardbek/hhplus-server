### 개요

하나의 트랜잭션에서 너무 많은 일을 처리하게 되면 **처리 속도 저하**와 **사용자 대기 시간 증가** 문제가 발생한다.

이를 해결하기 위해, 중요한 비즈니스 로직은 먼저 동기적으로 처리하고,

그 결과를 **이벤트로 비동기 전파**하여 후속 처리를 분리하는 **이벤트 기반 아키텍처**가 사용된다.

하지만 단순 이벤트 발행 방식에는 다음과 같은 단점이 있다.

1. **시스템 복잡도 증가**
(통합된 전송 영역이 없어 데이터 흐름을 파악하기 어려움)

2. **데이터 파이프라인 관리의 어려움**
3. **데이터 불일치로 인한 신뢰도 감소**

이러한 문제를 구조적으로 해결하기 위해 Kafka를 도입할 수 있다.

---

### Kafka의 주요 특징

- **고내구성**: 디스크 기반 저장으로 메시지 유실 방지
- **고처리량**: 초당 수백만 건 메시지 처리 가능
- **순서 보장**: 파티션 내 메시지 순서 유지
- **재처리 가능**: 오프셋 기반으로 특정 시점부터 재처리 가능
- **확장성**: 파티션 수 조절로 수평 확장 가능
- **Exactly Once 보장 (옵션)**: 중복 없는 정확한 메시지 처리 가능

---

### Kafka 도입 시 장점

### 1. **이벤트 흐름의 중앙 집중화**

- Kafka Topic을 통해 **어떤 이벤트가 언제, 어떤 서비스에 의해 발행되었는지 추적 가능**

### 2. **표준화된 데이터 전송 방식**

- Kafka가 제공하는 **표준 인터페이스 (Producer/Consumer API)** 사용
- 서비스 간 직접 연결 대신 **Kafka를 통한 간접 연결**로 구성 → **의존성 최소화**

### 3. **확장성과 신뢰성 강화**

- 새로운 Consumer 추가 시 기존 시스템 수정 없이 바로 연결 가능
- **메시지 유실 방지, 중복 방지, 순서 보장** 등 고신뢰 메시지 처리 지원

### 4. **개발자의 비즈니스 로직 집중 가능**

- 통신/전송 관련 인프라 복잡도는 Kafka에 위임하고,

  개발자는 **핵심 서비스 로직 구현에 집중 가능**


---

### Kafka 도입 시 단점 및 고려사항

### 1. **운영 복잡성 증가**

- Kafka는 단일 프로세스가 아니라 다수의 **Broker, ZooKeeper(KRaft), Topic, Partition**으로 구성된 분산 시스템
- 클러스터 관리, 장애 대응, 성능 튜닝에 대한 **운영 경험이 필수**

### 2. **모니터링 및 관찰성 부족**

- 메시지 유실·중복·순서 꼬임 여부를 Kafka만으로 파악하기 어려움
- **End-to-End 추적 기능 미비** → 별도 도구 (Prometheus, Grafana, Kafka Manager 등) 필수

### 3. **메시지 처리 실패에 대한 책임 분산**

- Kafka는 메시지를 발행·전달할 뿐, **처리 결과는 알 수 없음**
- 실패 시 **재처리, 보상 로직은 모두 Consumer 쪽에서 직접 구현**해야 함

### 4. **메시지 순서 보장 한계**

- Partition 단위로만 순서 보장
- **여러 Partition에 걸친 순서 제어는 불가능**
- 순서가 중요한 경우 **Partition Key 설계**가 매우 중요

### 5. **데이터 중복/유실 처리에 대한 설계 부담**

- Exactly Once 처리 가능하지만 구성 복잡
- 대부분 **At-Least-Once 또는 At-Most-Once** 처리를 선택하게 됨

### 6. **디버깅/장애 분석 어려움**

- Kafka는 메시지 발행/소비 이후 **내부 동작을 추적하기 어려움**
- 메시지가 누락된 경우, **어느 단계에서 문제가 발생했는지 식별이 어려움**

### Kafka의 구조와 데이터 흐름

Kafka는 **대규모 실시간 데이터 스트리밍을 위한 분산 메시지 시스템**이다.

다음과 같은 구성요소와 흐름을 통해 이벤트 데이터를 생산, 전파, 소비한다.

### 구성 요소

| 구성 요소 | 설명 |
| --- | --- |
| **Producer** | Kafka에 이벤트(메시지)를 발행하는 애플리케이션 |
| **Consumer** | Kafka에서 메시지를 구독하여 처리하는 애플리케이션 |
| **Topic** | 메시지가 분류되어 저장되는 논리적 채널 (DB의 테이블 개념) |
| **Partition** | Topic을 분할한 물리적 저장 단위. 병렬 처리 및 순서 보장을 위해 사용 |
| **Broker** | Kafka 서버 하나를 의미. 여러 Broker가 모여 Kafka 클러스터를 구성 |
| **Consumer Group** | 여러 Consumer가 하나의 작업을 병렬로 분담하여 처리하기 위한 단위 |
| **ZooKeeper / KRaft** | 클러스터 메타데이터 및 상태 관리를 담당. Kafka 3.5 이상에서는 KRaft로 대체 가능 |

---

### 데이터 흐름 요약

```
[Producer] → [Kafka Broker / Topic / Partition] → [Consumer]
```

### 동작 순서

1. **Producer가 메시지 발행**
    - 특정 Topic에 메시지를 전송
    - 메시지는 Round-Robin 또는 특정 Partition Key로 분산 저장
2. **Kafka Broker가 메시지를 저장**
    - 메시지는 **디스크 기반의 Append-Only 로그**로 저장됨
    - 각 메시지는 고유의 **Offset**을 가짐 (재처리/재시작 시 활용)
3. **Consumer가 메시지를 소비**
    - Consumer는 Topic을 구독하고, Offset 기준으로 메시지를 순차적으로 처리
    - 처리 후 **커밋(commit)** 하여 Offset 저장
4. **Consumer Group을 통한 병렬 처리**
    - 같은 Consumer Group 내에서 Partition 단위로 작업이 분산됨
    - 하나의 Partition은 하나의 Consumer만 소비 가능 → **순서 보장**

---


### 마무리

Kafka는 복잡한 이벤트 기반 시스템에서 **데이터 흐름의 일관성, 확장성, 내구성**을 확보할 수 있게 해준다.

하지만 도입 시에는 **운영, 모니터링, 설계 상의 추가 비용**을 충분히 고려가 필요하다.